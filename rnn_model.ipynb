{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rnn model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/whaledarn/MMRVaccineResearch/blob/main/rnn_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2KK6dkB7l0E",
        "outputId": "1626bf6c-6f97-408b-870f-7d8db3274ff7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import numpy as np\n",
        "from numpy import array\n",
        "\n",
        "import os\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "from preproc import tokenize\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "df = pd.read_excel(r'Tweets.xls')\n",
        "df2 = pd.read_excel(r'Data.xlsx')\n",
        "tweets = list(df['Field'])\n",
        "tone = list(df2['tone/emotion'])\n",
        "type = list(df2['type of message'])\n",
        "attitude = list(df2['attitude toward vaccine'])\n",
        "length_of_data = 2997\n",
        "seed = 50\n",
        "\n",
        "for i in range(0, length_of_data):\n",
        "    tweets[i] = tokenize(tweets[i])\n",
        "\n",
        "mapped = zip(tweets, tone, type, attitude)\n",
        "mapped = list(mapped)\n",
        "\n",
        "random.seed(seed)\n",
        "random.shuffle(mapped)\n",
        "\n",
        "train_tweets, train_tone, train_type, train_attitude = zip(*mapped[:2100])\n",
        "validation_tweets, validation_tone, validation_type, validation_attitude = zip(*mapped[2100:2400])\n",
        "testing_tweets, testing_tone, testing_type, testing_attitude = zip(*mapped[2400:])\n",
        "\n",
        "\n",
        "#               vvvv change for different tasks\n",
        "values = array(train_attitude)\n",
        "label_encoder = LabelEncoder()\n",
        "integer_encoded = label_encoder.fit_transform(values)\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
        "train_select = onehot_encoded\n",
        "\n",
        "values = array(validation_attitude)\n",
        "label_encoder = LabelEncoder()\n",
        "integer_encoded = label_encoder.fit_transform(values)\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
        "valid_select = onehot_encoded\n",
        "\n",
        "values = array(testing_attitude)\n",
        "label_encoder = LabelEncoder()\n",
        "integer_encoded = label_encoder.fit_transform(values)\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
        "testing_select = onehot_encoded\n",
        "\n",
        "\n",
        "\n",
        "tokenizer = Tokenizer(num_words=10000)\n",
        "tokenizer.fit_on_texts(train_tweets)\n",
        "train_tweets = tokenizer.texts_to_sequences(train_tweets)\n",
        "validation_tweets = tokenizer.texts_to_sequences(validation_tweets)\n",
        "testing_tweets = tokenizer.texts_to_sequences(testing_tweets)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "# A dictionary mapping words to an integer index\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "# The first indices are reserved\n",
        "word_index = {k:(v+3) for k,v in word_index.items()} \n",
        "word_index[\"<PAD>\"] = 0\n",
        "word_index[\"<START>\"] = 1\n",
        "word_index[\"<UNK>\"] = 2  # unknown\n",
        "word_index[\"<UNUSED>\"] = 3\n",
        "\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "def decode_review(text):\n",
        "    return ' '.join([reverse_word_index.get(i, '?') for i in text])\n",
        "\n",
        "train_data = keras.preprocessing.sequence.pad_sequences(train_tweets,\n",
        "                                                        value=word_index[\"<PAD>\"],\n",
        "                                                        padding='post',\n",
        "                                                        maxlen=50)\n",
        "\n",
        "valid_data = keras.preprocessing.sequence.pad_sequences(validation_tweets,\n",
        "                                                       value=word_index[\"<PAD>\"],\n",
        "                                                       padding='post',\n",
        "                                                       maxlen=50)\n",
        "testing_data = keras.preprocessing.sequence.pad_sequences(testing_tweets,\n",
        "                                                       value=word_index[\"<PAD>\"],\n",
        "                                                       padding='post',\n",
        "                                                       maxlen=50)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2Cutjfr_bOn",
        "outputId": "b7c24bd0-f3c8-4155-9fe2-dfc3b9b48678",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "from keras.layers import Embedding, LSTM, Conv1D, MaxPooling1D, GlobalMaxPooling1D \n",
        "\n",
        "# looks at the top 10000 words\n",
        "vocab_size = 10000\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Embedding(vocab_size, 200))\n",
        "model.add(keras.layers.LSTM(64, return_sequences=False, \n",
        "               dropout=0.1, recurrent_dropout=0.1))\n",
        "\n",
        "# Fully connected layer\n",
        "model.add(keras.layers.Dense(64, activation='relu'))\n",
        "\n",
        "# Dropout for regularization\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "\n",
        "model.add(keras.layers.Dense(3, activation=\"softmax\"))\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['acc'])\n",
        "\n",
        "\n",
        "history = model.fit(train_data,\n",
        "                    train_select,\n",
        "                    epochs=15,\n",
        "                    batch_size=64,\n",
        "                    validation_data=(valid_data, valid_select),\n",
        "                    verbose=0)\n",
        "\n",
        "results = model.evaluate(testing_data, testing_select)\n",
        "\n",
        "print(results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_6 (Embedding)      (None, None, 200)         2000000   \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 64)                67840     \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 3)                 195       \n",
            "=================================================================\n",
            "Total params: 2,072,195\n",
            "Trainable params: 2,072,195\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "597/597 [==============================] - 1s 874us/sample - loss: 0.7338 - acc: 0.7722\n",
            "[0.7338001903277546, 0.7721943]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}